{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batch_stimuli.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/pamsfwang/perceptual_learning/blob/master/batch_stimuli.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_WgrbweUOrkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GS2EVM8OOvKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3906a6a1-c465-4195-84c0-3c37d269ad1a"
      },
      "cell_type": "code",
      "source": [
        "#Mount Google drive on Colab\n",
        "#step01\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "#step02: code for mounting google drive on Linux\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "#step03: change directory to the google drive folder for the project\n",
        "os.getcwd()\n",
        "!ls\n",
        "os.chdir('./drive/Colab_files')\n",
        "os.getcwd()\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpe2b8869i/pubring.gpg' created\n",
            "gpg: /tmp/tmpe2b8869i/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "··········\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n",
            "drive\t\t\t     notebooks\n",
            "jfj_stimuli_param.csv\t     stimuli_param_uniqueF3.csv\n",
            "jfj_stimuli_param_test.csv   stimuli_param_uniqueF3_test_new.csv\n",
            "jfj_stimuli_param_train.csv  stimuli_param_uniqueF3_train_new.csv\n",
            "models\t\t\t     stimuli_param_uniqueF3_train_new.csv.ods\n",
            "drive\t\t\t     notebooks\n",
            "jfj_stimuli_param.csv\t     stimuli_param_uniqueF3.csv\n",
            "jfj_stimuli_param_test.csv   stimuli_param_uniqueF3_test_new.csv\n",
            "jfj_stimuli_param_train.csv  stimuli_param_uniqueF3_train_new.csv\n",
            "models\t\t\t     stimuli_param_uniqueF3_train_new.csv.ods\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vumRQeGbOymY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#specify variables\n",
        "train_data = 'stimuli_param_uniqueF3_train_new.csv' #'jfj_stimuli_param_train.csv'\n",
        "test_data = 'jfj_stimuli_param_test.csv'\n",
        "\n",
        "num_features = 3\n",
        "node_hidden01 = 10\n",
        "learning_rate = 0.005\n",
        "initial_weight01 = -0.001\n",
        "initial_weight02 = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQEhl_fLO9b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9dca01f8-f824-48a0-ad73-b808574f29e9"
      },
      "cell_type": "code",
      "source": [
        "#load data\n",
        "df=pd.read_csv(train_data, sep=',',header=None)\n",
        "df.shape\n",
        "nsamples =df.shape[0]\n",
        "print \"number of training samples:\",nsamples\n",
        "\n",
        "#shuffle the data\n",
        "df_array = df.values\n",
        "new = numpy.take(df_array,numpy.random.permutation(df_array.shape[0]),axis=0,out=df_array);\n",
        "\n",
        "##separate data into features and labels (numpy.array)\n",
        "temp = new[:,0:3] #df.iloc[:,0:num_features]\n",
        "x_data = temp #temp.values\n",
        "print \"dimension of feature dataset:\",x_data.shape\n",
        "print(x_data[0:5,:])\n",
        "\n",
        "temp = new[:,3]#df.iloc[:,num_features]\n",
        "y_data = temp #temp.values\n",
        "print \"dimension of category dataset:\",y_data.shape\n",
        "print(y_data[0:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training samples: 52\n",
            "dimension of feature dataset: (52, 3)\n",
            "[[1.  3.  3.1]\n",
            " [3.  3.  4.4]\n",
            " [2.  3.  3.4]\n",
            " [4.  1.  1.7]\n",
            " [1.  2.  0.3]]\n",
            "dimension of category dataset: (52,)\n",
            "[1. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tfrTpOcUPBUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##set up network layers\n",
        "#You can think of most the tensorflow variables as actually being functions that we will call when we want to get their value. \n",
        "input_ph = tf.placeholder(tf.float32, shape=[num_features, None]) \n",
        "#This will be the place the input to the network is inserted\n",
        "#shape: number of features\n",
        "#None: take in any size\n",
        "\n",
        "target_ph =  tf.placeholder(tf.float32, shape=[1,None]) \n",
        "#This will be the place the target for the network is insertedd\n",
        "#shape = number of node\n",
        "\n",
        "#First layer weights\n",
        "W1 = tf.Variable(tf.random_uniform([node_hidden01,num_features],initial_weight01,initial_weight02)) \n",
        "#first layer: 3 input feautres to 10 nodes in the hidden layer\n",
        "#W1: weights from item input to hidden layer 01\n",
        "b1 = tf.Variable(tf.random_uniform([node_hidden01,1],initial_weight01,initial_weight02)) # \" \" biases\n",
        "#one bias to the 10 nodes in the hidden layer\n",
        "#[# nodes, # nodes], sampling from a random uniform distribution from initial_weight01 to initial_weight02 for initial weights\n",
        "\n",
        "#Second layer\n",
        "W2 = tf.Variable(tf.random_uniform([1,node_hidden01],initial_weight01,initial_weight02)) \n",
        "#second layer: 10 nodes in the first hidden layer to one node in the second\n",
        "#W2: weights from hidden layer 01 to output layer\n",
        "b2 = tf.Variable(tf.random_uniform([1],initial_weight01,initial_weight02))\n",
        "\n",
        "\n",
        "#####\n",
        "##construct the network\n",
        "h1 = tf.nn.tanh(tf.matmul(W1,input_ph)+b1)\n",
        "#y = tanh(x1w11+x2w21)\n",
        "#tf.matmul: matrix multiplication\n",
        "\n",
        "output = tf.nn.sigmoid(tf.matmul(W2,h1)+b2) \n",
        "#This is the actual construction of the network. \n",
        "#When we want to get the output of the network, we will tell tensorflow what to put in the input placeholder, and then we'll run this output function\n",
        "\n",
        "loss = tf.reduce_sum(tf.square(output - target_ph))\n",
        "#This is the function we're trying to optimize. The reduce_sum is not really necessary since we only have a single output, just using it to flatten the output.\n",
        "\n",
        "#optimizer = tf.train.AdamOptimizer(learning_rate) \n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "#This is a fancy version of momentum based gradient descent optimization.\n",
        "\n",
        "train = optimizer.minimize(loss) \n",
        "#This will be how we tell the network to train on an example\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3M21q2RWPWrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    MSE = 0.0\n",
        "    for i in xrange(len(x_data)):\n",
        "      MSE += sess.run(loss,feed_dict={input_ph: x_data[i].reshape([3,1]),target_ph: y_data[i].reshape([1,1])}) #test on a test data point. feed_dict is how you pass things in to the placeholders created above\n",
        "    MSE /= len(x_data)\n",
        "    return MSE\n",
        "\n",
        "def accuracy():\n",
        "    temp =[] \n",
        "    for i in xrange(len(y_data)):\n",
        "        temp.append(sess.run(output,feed_dict={input_ph: x_data[i].reshape([3,1])}))\n",
        "    return temp\n",
        "    \n",
        "    \n",
        "def hidden():\n",
        "    temp = []\n",
        "    for i in xrange(len(y_data)):\n",
        "        temp.append(sess.run(h1,feed_dict={input_ph: x_data[i].reshape([3,1])}))\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sBorcVi1hPjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85827800-bd10-4591-b23f-2ade25ab276f"
      },
      "cell_type": "code",
      "source": [
        "inputfeature = numpy.transpose(x_data)\n",
        "print(inputfeature.shape)\n",
        "inputlabel = numpy.transpose(y_data)\n",
        "print(inputlabel.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 52)\n",
            "(52,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HXbfXPeMQRVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e5f39e02-0087-4dcf-8b7d-314c5f4b1c8b"
      },
      "cell_type": "code",
      "source": [
        "# Launch the graph -- tell tensorflow to initialize everything.\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init) #first argument to sess.run is function to run, here we're running the initialize function\n",
        "\n",
        "# Fit the function\n",
        "print \"Pre training MSE:\", test\n",
        "ac = []\n",
        "hid = []\n",
        "los = []\n",
        "\n",
        "for step in xrange(1):\n",
        "  for item in xrange(nsamples): \n",
        "    sess.run(train,feed_dict={input_ph: inputfeature,target_ph: inputlabel}) \n",
        "  #sess.run(train): this will train the model, update the weights\n",
        "  #Run training on an example\n",
        "  ac.append(accuracy())\n",
        "  hid.append(hidden())\n",
        "  los.append(test())\n",
        "  if step % 100 == 0:\n",
        "    print \"On step %i, test MSE %f\" %(step,test())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre training MSE: <function test at 0x7fd080e5cde8>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-a839cbddf8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;31m#sess.run(train): this will train the model, update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m#Run training on an example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1111\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1112\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (52,) for Tensor u'Placeholder_17:0', which has shape '(1, ?)'"
          ]
        }
      ]
    }
  ]
}