{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "\n",
    "#Data generation, probably a better way to do this\n",
    "#x_data = numpy.floor(2*numpy.random.random([nsamples,2]))-1\n",
    "#y_data = numpy.array(map(lambda x: (x[0] or x[1]) and not (x[0] and x[1]),x_data))\n",
    "#y_data = y_data.reshape([nsamples,1])\n",
    "\n",
    "test_x_data = numpy.array([[-1,-1],[-1,1],[1,-1],[1,1]])\n",
    "test_y_data = numpy.array([[-1],[1],[1],[-1]])\n",
    "\n",
    "#Just a way of choosing data from this set\n",
    "data_indices = numpy.random.choice(range(len(test_x_data)),nsamples)\n",
    "x_data = numpy.array(test_x_data[data_indices]) \n",
    "y_data = numpy.array(test_y_data[data_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can think of most the tensorflow variables as actually being functions that we will call when we want to get their value. \n",
    "input_ph = tf.placeholder(tf.float32, shape=[3,1]) #This will be the place the input to the network is inserted\n",
    "target_ph =  tf.placeholder(tf.float32, shape=[1,1]) #This will be the place the target for the network is insertedd\n",
    "W1 = tf.Variable(tf.random_uniform([10,3],-1,1)) #First layer weights\n",
    "b1 = tf.Variable(tf.random_uniform([2,1],-1,1)) # \" \" biases\n",
    "W2 = tf.Variable(tf.random_uniform([1,2],-1,1)) #2nd layer\n",
    "b2 = tf.Variable(tf.random_uniform([1],-1,1))\n",
    "output = tf.nn.tanh(tf.matmul(W2,tf.nn.tanh(tf.matmul(W1,input_ph)+b1))+b2) #This is the actual construction of the network. When we want to get the output of the network, we will tell tensorflow what to put in the input placeholder, and then we'll run this output function\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(output - target_ph)) #This is the function we're trying to optimize. The reduce_sum is not really necessary since we only have a single output, just using it to flatten the output.\n",
    "optimizer = tf.train.AdamOptimizer(0.005) #This is a fancy version of momentum based gradient descent optimization.\n",
    "train = optimizer.minimize(loss) #This will be how we tell the network to train on an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph -- tell tensorflow to initialize everything.\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) #first argument to sess.run is function to run, here we're running the initialize function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre training MSE: <function test at 0x1147060c8>\n",
      "On step 0, test MSE 1.422621\n",
      "On step 100, test MSE 1.026582\n",
      "On step 200, test MSE 0.694327\n",
      "On step 300, test MSE 0.533860\n",
      "On step 400, test MSE 0.415480\n",
      "On step 500, test MSE 0.316724\n",
      "On step 600, test MSE 0.243753\n",
      "On step 700, test MSE 0.187656\n",
      "On step 800, test MSE 0.149329\n",
      "On step 900, test MSE 0.118296\n",
      "On step 1000, test MSE 0.095347\n",
      "On step 1100, test MSE 0.079113\n",
      "On step 1200, test MSE 0.065957\n",
      "On step 1300, test MSE 0.055717\n",
      "On step 1400, test MSE 0.048040\n",
      "On step 1500, test MSE 0.041520\n",
      "On step 1600, test MSE 0.036399\n",
      "On step 1700, test MSE 0.031909\n",
      "On step 1800, test MSE 0.028408\n",
      "On step 1900, test MSE 0.025109\n",
      "On step 2000, test MSE 0.022310\n",
      "On step 2100, test MSE 0.020061\n",
      "On step 2200, test MSE 0.018043\n",
      "On step 2300, test MSE 0.016315\n",
      "On step 2400, test MSE 0.014870\n",
      "On step 2500, test MSE 0.013535\n",
      "On step 2600, test MSE 0.012418\n",
      "On step 2700, test MSE 0.011358\n",
      "On step 2800, test MSE 0.010484\n",
      "On step 2900, test MSE 0.009610\n",
      "On step 3000, test MSE 0.008820\n",
      "On step 3100, test MSE 0.008155\n",
      "On step 3200, test MSE 0.007529\n",
      "On step 3300, test MSE 0.006975\n",
      "On step 3400, test MSE 0.006493\n",
      "On step 3500, test MSE 0.006030\n",
      "On step 3600, test MSE 0.005631\n",
      "On step 3700, test MSE 0.005241\n",
      "On step 3800, test MSE 0.004911\n",
      "On step 3900, test MSE 0.004572\n",
      "On step 4000, test MSE 0.004257\n",
      "On step 4100, test MSE 0.003985\n",
      "On step 4200, test MSE 0.003724\n",
      "On step 4300, test MSE 0.003489\n",
      "On step 4400, test MSE 0.003280\n",
      "On step 4500, test MSE 0.003076\n",
      "On step 4600, test MSE 0.002898\n",
      "On step 4700, test MSE 0.002721\n",
      "On step 4800, test MSE 0.002568\n",
      "On step 4900, test MSE 0.002410\n",
      "On step 5000, test MSE 0.002261\n",
      "On step 5100, test MSE 0.002130\n",
      "On step 5200, test MSE 0.002003\n",
      "On step 5300, test MSE 0.001888\n",
      "On step 5400, test MSE 0.001785\n",
      "On step 5500, test MSE 0.001682\n",
      "On step 5600, test MSE 0.001593\n",
      "On step 5700, test MSE 0.001502\n",
      "On step 5800, test MSE 0.001424\n",
      "On step 5900, test MSE 0.001342\n",
      "On step 6000, test MSE 0.001264\n",
      "On step 6100, test MSE 0.001196\n",
      "On step 6200, test MSE 0.001129\n",
      "On step 6300, test MSE 0.001067\n",
      "On step 6400, test MSE 0.001012\n",
      "On step 6500, test MSE 0.000957\n",
      "On step 6600, test MSE 0.000908\n",
      "On step 6700, test MSE 0.000859\n",
      "On step 6800, test MSE 0.000816\n",
      "On step 6900, test MSE 0.000772\n",
      "On step 7000, test MSE 0.000729\n",
      "On step 7100, test MSE 0.000691\n",
      "On step 7200, test MSE 0.000653\n",
      "On step 7300, test MSE 0.000619\n",
      "On step 7400, test MSE 0.000588\n",
      "On step 7500, test MSE 0.000557\n",
      "On step 7600, test MSE 0.000530\n",
      "On step 7700, test MSE 0.000502\n",
      "On step 7800, test MSE 0.000478\n",
      "On step 7900, test MSE 0.000452\n",
      "On step 8000, test MSE 0.000428\n",
      "On step 8100, test MSE 0.000406\n",
      "On step 8200, test MSE 0.000384\n",
      "On step 8300, test MSE 0.000365\n",
      "On step 8400, test MSE 0.000347\n",
      "On step 8500, test MSE 0.000329\n",
      "On step 8600, test MSE 0.000313\n",
      "On step 8700, test MSE 0.000297\n",
      "On step 8800, test MSE 0.000283\n",
      "On step 8900, test MSE 0.000268\n",
      "On step 9000, test MSE 0.000254\n",
      "On step 9100, test MSE 0.000241\n",
      "On step 9200, test MSE 0.000229\n",
      "On step 9300, test MSE 0.000217\n",
      "On step 9400, test MSE 0.000207\n",
      "On step 9500, test MSE 0.000196\n",
      "On step 9600, test MSE 0.000187\n",
      "On step 9700, test MSE 0.000177\n",
      "On step 9800, test MSE 0.000169\n",
      "On step 9900, test MSE 0.000160\n",
      "Post training MSE: 0.000151952792294\n",
      "Final weights:\n",
      "(array([[ 1.9876231 ,  1.99150681],\n",
      "       [ 1.9347868 ,  1.93075371]], dtype=float32), array([[ 1.77694678],\n",
      "       [-1.71790457]], dtype=float32), array([[ 2.76028538, -2.76443911]], dtype=float32), array([-2.52606583], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    MSE = 0.0\n",
    "    for i in xrange(len(test_x_data)):\n",
    "\tMSE += sess.run(loss,feed_dict={input_ph: test_x_data[i].reshape([2,1]),target_ph: test_y_data[i].reshape([1,1])}) #test on a test data point. feed_dict is how you pass things in to the placeholders created above\n",
    "    MSE /= 4\n",
    "    return MSE\n",
    "\n",
    "# Fit the function\n",
    "print \"Pre training MSE:\", test\n",
    "for step in xrange(10000):\n",
    "    sess.run(train,feed_dict={input_ph: x_data[step % nsamples].reshape([2,1]),target_ph: y_data[step % nsamples].reshape([1,1])}) #Run training on an example\n",
    "    if step % 100 == 0:\n",
    "\tprint \"On step %i, test MSE %f\" %(step,test())\n",
    "\n",
    "print \"Post training MSE:\", test()\n",
    "\n",
    "print \"Final weights:\"\n",
    "print(sess.run(W1),sess.run(b1),sess.run(W2),sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
