{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "\n",
    "#Data generation, probably a better way to do this\n",
    "#x_data = numpy.floor(2*numpy.random.random([nsamples,2]))-1\n",
    "#y_data = numpy.array(map(lambda x: (x[0] or x[1]) and not (x[0] and x[1]),x_data))\n",
    "#y_data = y_data.reshape([nsamples,1])\n",
    "\n",
    "test_x_data = numpy.array([[-1,-1],[-1,1],[1,-1],[1,1]])\n",
    "test_y_data = numpy.array([[-1],[1],[1],[-1]])\n",
    "\n",
    "#Just a way of choosing data from this set\n",
    "data_indices = numpy.random.choice(range(len(test_x_data)),nsamples)\n",
    "x_data = numpy.array(test_x_data[data_indices]) \n",
    "y_data = numpy.array(test_y_data[data_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can think of most the tensorflow variables as actually being functions that we will call when we want to get their value. \n",
    "input_ph = tf.placeholder(tf.float32, shape=[2,1]) #This will be the place the input to the network is inserted\n",
    "target_ph =  tf.placeholder(tf.float32, shape=[1,1]) #This will be the place the target for the network is insertedd\n",
    "W1 = tf.Variable(tf.random_uniform([2,2],-1,1)) #First layer weights\n",
    "b1 = tf.Variable(tf.random_uniform([2,1],-1,1)) # \" \" biases\n",
    "W2 = tf.Variable(tf.random_uniform([1,2],-1,1)) #2nd layer\n",
    "b2 = tf.Variable(tf.random_uniform([1],-1,1))\n",
    "h1 = tf.nn.tanh(tf.matmul(W1,input_ph)+b1)\n",
    "output = tf.nn.tanh(tf.matmul(W2,h1)+b2) #This is the actual construction of the network. When we want to get the output of the network, we will tell tensorflow what to put in the input placeholder, and then we'll run this output function\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(output - target_ph)) #This is the function we're trying to optimize. The reduce_sum is not really necessary since we only have a single output, just using it to flatten the output.\n",
    "optimizer = tf.train.AdamOptimizer(0.005) #This is a fancy version of momentum based gradient descent optimization.\n",
    "train = optimizer.minimize(loss) #This will be how we tell the network to train on an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph -- tell tensorflow to initialize everything.\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) #first argument to sess.run is function to run, here we're running the initialize function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre training MSE: <function test at 0x114861668>\n",
      "On step 0, test MSE 0.072832\n",
      "On step 100, test MSE 0.062577\n",
      "On step 200, test MSE 0.054648\n",
      "On step 300, test MSE 0.047694\n",
      "On step 400, test MSE 0.042585\n",
      "On step 500, test MSE 0.037972\n",
      "On step 600, test MSE 0.033583\n",
      "On step 700, test MSE 0.030264\n",
      "On step 800, test MSE 0.027396\n",
      "On step 900, test MSE 0.024916\n",
      "Post training MSE: 0.0225567873567\n",
      "Final weights:\n",
      "(array([[-1.59539008,  1.59060919],\n",
      "       [ 1.49789572, -1.49995673]], dtype=float32), array([[-1.34111702],\n",
      "       [-1.24657249]], dtype=float32), array([[ 1.52388096,  1.54994309]], dtype=float32), array([ 1.24373245], dtype=float32))\n",
      "[[-0.87078941]\n",
      " [-0.84673744]]\n",
      "[[ 0.95126158]\n",
      " [-0.99958861]]\n",
      "[[-0.99976623]\n",
      " [ 0.94152093]]\n",
      "[[-0.87308156]\n",
      " [-0.84790003]]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    MSE = 0.0\n",
    "    for i in xrange(len(test_x_data)):\n",
    "\tMSE += sess.run(loss,feed_dict={input_ph: test_x_data[i].reshape([2,1]),target_ph: test_y_data[i].reshape([1,1])}) #test on a test data point. feed_dict is how you pass things in to the placeholders created above\n",
    "    MSE /= 4\n",
    "    return MSE\n",
    "\n",
    "# Fit the function\n",
    "print \"Pre training MSE:\", test\n",
    "for step in xrange(10000):\n",
    "    sess.run(train,feed_dict={input_ph: x_data[step % nsamples].reshape([2,1]),target_ph: y_data[step % nsamples].reshape([1,1])}) #Run training on an example\n",
    "    if step % 100 == 0:\n",
    "\tprint \"On step %i, test MSE %f\" %(step,test())\n",
    "\n",
    "print \"Post training MSE:\", test()\n",
    "\n",
    "print \"Final weights:\"\n",
    "\n",
    "print(sess.run(W1),sess.run(b1),sess.run(W2),sess.run(b2))\n",
    "print(sess.run(h1,feed_dict={input_ph: test_x_data[0].reshape([2,1])}))\n",
    "print(sess.run(h1,feed_dict={input_ph: test_x_data[1].reshape([2,1])}))\n",
    "print(sess.run(h1,feed_dict={input_ph: test_x_data[2].reshape([2,1])}))\n",
    "print(sess.run(h1,feed_dict={input_ph: test_x_data[3].reshape([2,1])}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
